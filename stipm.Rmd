---
title: "stipm"
author: "dan.auerbach@dfw.wa.gov modifying DeFilippo et al. 2021 in consultation with Thomas.Buehrens@dfw.wa.gov"
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
output: 
  wdfwTemplates::wdfw_html_format

---

This script updates and extends the [original implementation](https://github.com/lukasdefilippo/ST-IPM) of [DeFilippo et al.'s (2021)](https://www.sciencedirect.com/science/article/pii/S0165783621001429) "Spatiotemporal Integrated Population Model" (ST-IPM) of Washington state natural origin coho (*O. kisutch*) returns, with initial application to annual preseason forecasts of Willapa Bay returning adults.

# setup

```{r setup, results = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, results = FALSE, warning = FALSE, message = FALSE)

library("tidyverse")
library("gt")
library("odbc"); library("DBI")
library("rstan")
options(mc.cores = 10) #12 on DA machine
rstan_options(auto_write = TRUE)
theme_set(theme_light())

f_orig <- "Coho_IPM_spatial_AR.r"

fp <- list(
  fram_file = "data/postseason_fram_spwn_hvst_ests.csv",
  coho_file = 'Coho data_3-30-20.csv',
  cwt_file = 'CWT_FRAM_Matches_complete20200303.csv',
  stream_file = 'Coho_KM_3.31.2020_2.csv'
  )

# # #lu_stock <- readxl::read_excel("stipm_pops_crosscheck.xlsx")
# # #lu_stock |> filter(FRAM_StockID != 13, FRAM_StockID != 43) |> pluck("FRAM_StockID") |> paste0(collapse = ",")
# # #drop FRAM StockID 13 and 43, original pop_ids 10 and 24
# fram_stocks <- c(105,93,89,45,51,55,75,81,61,23,149,63,107,115,111,157,97,135,153,101,69,1,85,139,131,127,145,11,17,59,35,29,117,161)

#can convert to csv etc. as needed
#may drop orig 10 and 24 from xlsx and reindex? and then drop filter...
#for now pop_id reindexing in objects below
#cannot reindex here b/c still joining orig tbl_coho smolt and CWT data
#(prefer not to, but could do joins from orig csv on pop name strings rather than numeric index...)
pop_meta <- readxl::read_excel("pop_meta.xlsx") |>
  dplyr::select(pop_id:hat) |>
  dplyr::filter(StockID != 13, StockID != 43)

# maybe_drop_popids <- c(
# #these should probably go...
#   10, #not sure what this actually is...
#   24, #Pt Gamble, fixed BKFRAM input, not a pop
# #these maybe...
#   14, #Dungeness, recent estimate difficulties, but smolt ests
#   16, #Elwha, recent method changes and special habitat case 
#   18, #Green, relevance, recent estimate difficulties, but smolt ests
#   21, #LkWA, relevance/pop size
#   23 #Nooksack, proxy not an escp est, but smolt ests
#   )

load("stipm.Rdata")

```

# data

The analysis relies on per-stock escapement and harvest estimates compiled in post-season [coho FRAM](https://github.com/FRAMverse/fram_doc) runs as well as CWT-based marine survival estimates derived from RMIS, and smolt outmigrant estimates compiled by WDFW.

## FRAM postseason estimates of spawning escapement and harvest mortality

Coho FRAM tracks age 3 fish across 5 time steps corresponding to a calendar year. It includes unmarked and marked units of both natural and hatchery stocks. 

Data in the best available database extend to 1986, but all values prior to 1998 and some prior to 2004 are of unknown origin.

```{r fram_readers, eval=FALSE}
read_coho_backwards <- function (db, runs = NULL, stocks = NULL) {

  db_con <- DBI::dbConnect(drv = odbc::odbc(),
    .connection_string = paste0("Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=", db, ";"))

  #lazy, full table then reduce as specified
  bk <- dplyr::tbl(db_con, "BackwardsFRAM") |> dplyr::select(RunID, StockID, escp = TargetEscAge3)
  if (!is.null(runs)) { bk <- dplyr::filter(bk, RunID %in% runs) }
  if (!is.null(stocks)) { bk <- dplyr::filter(bk, StockID %in% stocks) }

  #associate metainfo and pull
  bk <- bk |> 
    dplyr::left_join(
      dplyr::tbl(db_con, "RunID") |>  dplyr::select(RunID, RunYear, RunName), 
      by = "RunID") |>
    dplyr::left_join(
      dplyr::tbl(db_con, "Stock") |> dplyr::filter(Species == "COHO") |> dplyr::select(StockID, StockLongName),
      by = "StockID") |>
    dplyr::collect() |> 
    dplyr::arrange(RunYear, StockID)

  DBI::dbDisconnect(db_con)
  
  return(bk)
}

read_coho_escapement <- function (db, runs = NULL, stocks = NULL) {

  db_con <- DBI::dbConnect(drv = odbc::odbc(),
    .connection_string = paste0("Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=", db, ";"))
  #coho is already only age 3 in TimeStep 5
  #lazy, full table then reduce as specified
  escp <- dplyr::tbl(db_con, "Escapement") |> dplyr::select(RunID, StockID, escp = Escapement)
  if (!is.null(runs)) { escp <- dplyr::filter(escp, RunID %in% runs) }
  if (!is.null(stocks)) { escp <- dplyr::filter(escp, StockID %in% stocks) }

  #associate metainfo and pull
  escp <- escp |> 
    dplyr::left_join(
      dplyr::tbl(db_con, "RunID") |>  dplyr::select(RunID, RunYear, RunName), 
      by = "RunID") |>
    dplyr::left_join(
      dplyr::tbl(db_con, "Stock") |> dplyr::filter(Species == "COHO") |> dplyr::select(StockID, StockLongName),
      by = "StockID") |>
    dplyr::collect() |> 
    dplyr::arrange(RunYear, StockID)

  DBI::dbDisconnect(db_con)
  
  return(escp)
}

read_coho_mort <- function (db, runs = NULL, stocks = NULL) {
  
  db_con <- DBI::dbConnect(drv = odbc::odbc(),
    .connection_string = paste0("Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=", db, ";"))
  
  #lazy, full table then reduce as specified
  m <- dplyr::tbl(db_con, "Mortality") |> dplyr::select(-PrimaryKey)
  if (!is.null(runs)) { m <- dplyr::filter(m, RunID %in% runs) }
  if (!is.null(stocks)) { m <- dplyr::filter(m, StockID %in% stocks) }

  #associate metainfo and pull
  m <- m |> 
    dplyr::left_join(
      dplyr::tbl(db_con, "RunID") |>  dplyr::select(RunID, RunYear, RunName), 
      by = "RunID") |>
    dplyr::left_join(
      dplyr::tbl(db_con, "Stock") |> dplyr::filter(Species == "COHO") |> dplyr::select(StockID, StockLongName),
      by = "StockID") |>
    dplyr::left_join(
      dplyr::tbl(db_con, "Fishery") |> dplyr::filter(Species == "COHO") |> dplyr::select(FisheryID, FisheryName), 
      by = "FisheryID") |> 
    dplyr::collect() |> 
    dplyr::arrange(RunYear, FisheryID, TimeStep, StockID)

  DBI::dbDisconnect(db_con)
  
  return(m)
}
```

```{r read_fram_tables, eval=FALSE}
#the relevant data are queried and re-exported as csv
#stays similar to original and allows greater reproducibility/portability
mdb <- "O:/code/coho_fram_validation/PSC_CoTC_PostSeason_CohoFRAMDB_thru2019_021021.mdb"
#appears to be a mysterious RunID 3 in the Escapement and Mortality tables but not RunID table...
#aggregate mortality across timesteps for all sources to "estimated total harvest related impacts"
fram <- full_join(
  read_coho_escapement(mdb, stocks = pop_meta$FRAM_StockID) |> 
    filter(!is.na(RunYear))
  ,
  read_coho_mort(mdb, stocks = pop_meta$FRAM_StockID) |>
    filter(!is.na(RunYear)) |> 
    mutate(mort = LandedCatch + NonRetention + Shaker + DropOff + MSFLandedCatch + MSFNonRetention + MSFShaker + MSFDropOff) |> 
    group_by(RunYear, StockID, StockLongName) |> 
    summarise(mort = sum(mort), .groups = "drop")
  ,
  by = c("RunYear", "StockID", "StockLongName")
  ) |> 
  select(year = RunYear, StockID, StockLongName, spwn = escp, hvst = mort)

#fram |> filter(StockID == 161) |> print(n = 100)

write_csv(fram, "data/postseason_fram_spwn_hvst_ests.csv")

```

## Smolt outmigrant estimates

pending updates from ML

## RMIS releases and recoveries for marine survival

pending updates from NK

## full dataset

```{r tbl_coho_full, eval=FALSE}
#moving towards deletion
#still working on smolt and CWT updates

drop_pop <- c("Queets", "Clearwater", 'Bell Creek', 'Johnson Creek', 'Jimmy Come Lately Creek',
              'Deep Creek', 'McDonald Creek', 'Siebert Creek', 'Salt Creek', 'Discovery Bay',
              'East Twin Creek', 'West Twin Creek', 'Northeast Hood Canal')

drop_cwt_surv <- c("Minter Crk H", "Baker H", "Satsop H") 

tbl_coho <- readr::read_csv(fp$coho_file, show_col_types = FALSE) |> #1709x21
  mutate(
    pop = case_when(
      !is.na(`SaSI Population`) ~ `SaSI Population`,
      is.na(`SaSI Population`) & is.na(SubPopulation) ~ `Managment Unit (FRAM)`,
      is.na(`SaSI Population`) & !is.na(SubPopulation) ~ SubPopulation
    ),
    spwn = case_when(
      !is.na(`SaSI Population`) ~ `SASI Natural Origin Abundance`,
      is.na(`SaSI Population`) & is.na(SubPopulation) ~ `Age 3 Escapement (FRAM)`,
      is.na(`SaSI Population`) & !is.na(SubPopulation) ~ `SupPopulation Escapement`
    ),
    spwn = if_else(pop=="Discovery Bay", `SASI CompositeOrigin Abundance`, abs(spwn)) #corrects negative val for 2005 A12A Wild, orig L152
    ,
    hvst = spwn / (1/`Harvest (% FRAM)` - 1) 
  ) |> 
  filter( !(pop %in% drop_pop) ) |> 
  select(`Calendar Year`, `Smolt Abundance`, Latitude, Longitude, pop, spwn, hvst) |> 
  inner_join(
    readr::read_csv(fp$stream_file, show_col_types = FALSE) |> 
      filter(Population != "", !is.na(Population)) |> #no NAs in the current csv, but left for now
      select(pop = Population, KM)
    ,
    by = "pop") |> 
  full_join(
    readr::read_csv(fp$cwt_file, show_col_types = FALSE) |> 
      mutate(
        hat = if_else(stringr::str_detect(`Smolt Ocean Survival Population`, " H$"), 1, 0)
      ) |> 
      filter( !(`Smolt Ocean Survival Population` %in% drop_cwt_surv)) |> 
      select(pop = `Managment Unit (FRAM)`, `Calendar Year`, `Smolt Ocean Survival Population`, Fishery_Plus_Escapement, Release_No, hat)
    ,
    by = c("pop", "Calendar Year")) |> 
  filter(`Calendar Year` > 1985) |> 
  bind_rows(
    tibble(`Calendar Year` = 2013, yr = 28, pop = "Area 7-7A Independent Wild"),
    tibble(`Calendar Year` = 2004, yr = 19, pop = "Port Gamble Bay Wild"),
    tibble(`Calendar Year` = 2000:2001, yr = 15:16, pop = "Grays Harbor Miscellaneous Wild")
  ) |>
  left_join(
    bind_rows(
      tibble(pop = "Green River Wild", Long = -122.2145, Lat = 47.3519),
      tibble(pop = "Area 10E Miscellaneous Wild", Long = -122.8242, Lat = 47.5896)
    )
    , by = "pop") |>
  mutate(
    Longitude = if_else(is.na(Long), Longitude, Long), Long = NULL,
    Latitude = if_else(is.na(Lat), Latitude, Lat), Lat = NULL,
    Basin = if_else(Longitude < -123.80, 0, 1),
    `Smolt Abundance` = if_else(pop == "Puyallup River Wild", NA_real_, `Smolt Abundance`),
    hvst = if_else(stringr::str_detect(pop, "Quillayute River") & `Calendar Year` <= 1987, NA_real_, hvst),
    pop_id = as.numeric(factor(pop)),
    yr = `Calendar Year` - min(`Calendar Year`) + 1
  ) |> 
  rename(year = `Calendar Year`) |> 
  arrange(pop)

sf_coord <- tbl_coho |> 
  group_by(pop, pop_id) |> 
  summarise(long = median(Longitude, na.rm = T), lat = median(Latitude, na.rm = T), .groups = "drop") |> 
  sf::st_as_sf(coords = c("long", 'lat'), crs = sf::st_crs("+proj=longlat +datum=WGS84")) |> 
  sf::st_transform(crs = sf::st_crs("+proj=utm +zone=10T ellps=WGS84"))

```

```{r updating_full_dataset, eval=FALSE}
#Note pop_id reindexing here
#can/should do furthest upstream in popmeta

#note also the negative escapement in A12A Wild in 2005 is still an issue (from the FRAM database)
#so spwn is coerced to 0 here, but harvest is unaffected b/c drawn directly from Mortality
#rather than inversion of spwn via ER
coho_data_tbl <- pop_meta |> #only 34 rows but pop_id through 36
  left_join(read_csv(fp$fram_file), by = c("StockID", "StockLongName")) |> #filter(spwn < 0 | hvst < 0)
  mutate(spwn = if_else(spwn < 0, 0.01, spwn)) |> #filter(spwn < 0 | hvst < 0)
  left_join(
    tbl_coho |> select(pop_id, year, smolt = `Smolt Abundance`, est_n_rec = Fishery_Plus_Escapement, est_n_rel = Release_No)
    ,
    by = c("pop_id", "year")
  ) |> 
  mutate(
    rtrn = spwn + hvst,
    #reindex
    pop_id = as.numeric(factor(pop))
  ) |> 
  arrange(pop, year)

#coho_data_tbl |> distinct(pop_id, pop) |> print(n = 100)
#coho_data_tbl |> filter(StockID == 161) |> print(n = 100)

sf_coord <- pop_meta |> 
  mutate( pop_id = as.numeric(factor(pop)) ) |> 
  sf::st_as_sf(coords = c("lon", 'lat'), crs = sf::st_crs("+proj=longlat +datum=WGS84")) |> 
  sf::st_transform(crs = sf::st_crs("+proj=utm +zone=10T ellps=WGS84"))

# ggplot(sf_coord) + geom_sf(aes(color = hab_km, size = hab_km)) + geom_sf_text(aes(label = pop_id))

```


# model fitting

The STIPM and AR1 stan models are first repeatedly fit to progressive subsets of the data filtered by year in order to gauge "as applied" forecast skill. Rather than a "sliding window" (e.g., the prior 10 years stepped forward each year), the dataset is "stretched" from a fixed starting year. Although older observations may have less immediate relevance to current conditions, this approach allows the MCMC sampler to explore a larger parameter space for posterior distributions. Future work could compare skill with a sliding alternative to test the hypothesis that a more constrained but more recent span of years could improve prediction.

In practice, the data available to forecast a given year return may be limited to observations from one, two or even three years prior. These lags can vary by data type and source.

For example, a 2022 preseason forecast, made in January of 2022, would mostly likely have available:
  - Smolt outmigrant abundances from 2021
  - CWT recoveries & releases (informing marine survival) from 2020; from 2017 brood, released in 2019 with recoveries in 2020
  - FRAM-based estimates of harvest and escapement (informing annual total return) from 2019 or 2020
    - 2019 values are complete from the previous preseason planning process
    - 2020 estimates exist and are being compiled for Jan/Feb CoTC post-season runs
    - preliminary 2021 escapement estimates may be available, but will still be in review and undergoing regional QAQC
    
Accordingly, the process here examines 2 likely dataset scenarios for a forecast targeting year $y$:
  - STIPM: $smolt_{y-1}$, $MS_{y-2}$, $spwn_{y-2}, hvst_{y-2}$ or $spwn_{y-3}, hvst_{y-3}$
  - AR1: $spwn_{y-2}, hvst_{y-2}$ or $spwn_{y-3}, hvst_{y-3}$

## stan functions

A helper function trims years from the complete dataset according to arguments controlling the data-type-specific lag from a data `year_max` corresponding to the year before the desired forecast year (i.e., a `year_max` of 2021 designates the most recent possible data for the 2022 forecast). 

```{r stan_data_filter}
#trim years then declare separate intermediaries
#"year_max" is "last/max year of available data", so desired year_pred-1
#lags allow for flexible OAT configurations with additional trimming
#but can be zeroed to allow all available data
#for a 2022 forecast in adult_pred vectors from stan
#year_max is 2021, s.t. firmly available postseason FRAM is 2019 
stan_data_filter <- function(
  full, #complete dataset
  year_min, #starting anchor year
  #in STIPM, adult_pred[year_max+1] is a total return from smolt[year_max]*surv[year_max], with adult_est[year_max] as the spawning escapement
  #in AR1, adult_est and adult_pred are total return, and adult_pred[year_pred] is same as last year of adult_est b/c passing n_year+1 relative to STIPM
  year_max,
  lag_smolt = 0, #n-extra-years trimmed from smolt abundances 
  lag_MS = 1, #n-extra-years trimmed from release and recovery data
  lag_spwn = 2, #n-extra-years trimmed from FRAM escapement
  lag_hvst = 2 #n-extra-years trimmed from FRAM harvest
  ){
  
  full_ymin_ymax = filter(full, between(year, year_min, year_max)) |> 
    mutate(yr = year - min(year) + 1)
  
  stan_data = list(
    y_min_max = year_min:year_max,
    
    # smolt = filter(full_ymin_ymax, !is.na(`Smolt Abundance`), year <= year_max - lag_smolt),
    # MS = filter(full_ymin_ymax, !is.na(Release_No), year <= year_max - lag_MS),
    smolt = filter(full_ymin_ymax, !is.na(smolt), year <= year_max - lag_smolt),
    MS = filter(full_ymin_ymax, !is.na(est_n_rec), year <= year_max - lag_MS),
    
    spwn = filter(full_ymin_ymax, !is.na(spwn), year <= year_max - lag_spwn),
    hvst = filter(full_ymin_ymax, !is.na(hvst), year <= year_max - lag_hvst) |> 
      mutate(hvst = abs(hvst)),
    rtrn = full_ymin_ymax |> 
      #mutate(rtrn = spwn + abs(hvst)) |>
      filter(!is.na(rtrn), year <= year_max - max(c(lag_spwn, lag_hvst)))
  )
  
  return(stan_data)
}

# #tests, random start year
# stan_data_filter(coho_data_tbl, 2004, 2006) |> map(tail) #predicting 2007, with defaults only get FRAM through 2004
# stan_data_filter(coho_data_tbl, 2004, 2007) |> map(tail) #predicting 2008, defaults give FRAM 2005

```

**Note this uses `tbl_coho` for the "full" number of populations, which should generally equal the number with spwn+hvst values from FRAM. Could hard-code a numeric value after settling on a final population set (e.g., 34).**

Next, wrappers to the `rstan::stan` function facilitate repeated fitting with consistent control parameters and input data lists.

```{r ar1_functions}
stan_ar1 <- function(stan_data, n_iter = 200, n_chain = 2){
  #note following orig naming convention where "tot" refers to "total return" = spwn + hvst = rtrn, as estimated from FRAM
  stan_fit <- stan(
    file = 'LD_coho_forecast_AR_ind_2.stan',
    iter = n_iter, chains = n_chain, thin = 1, seed = 222,
    control = list(adapt_delta = 0.99, max_treedepth = 10.25),
    data = list(
      n_year = length(stan_data$y_min_max) + 1, #sets year of adult_pred and year-dim of adult_est 
#n_pop = length(unique(tbl_coho$pop_id)), #number of populations in full dataset (should generally equal n_pop_tot with)
      n_pop = length(unique(coho_data_tbl$pop_id)), #number of populations in full dataset
      n_pop_tot = length(unique(stan_data$rtrn$pop_id)), #Number of populations with return data
      pop_tot = unique(stan_data$rtrn$pop_id), #Which populations possess return data
      n_tot = length(stan_data$rtrn$rtrn), #Length of the return data vectors
      tot_dat = stan_data$rtrn$rtrn,  #Vectors of all return data across all populations
      tot_true = stan_data$rtrn$yr, #Vectors of the indices identifying which years are those with non-NA data for the return data
      #Paired vectors of slice points indicating the beginning, and end of the data for a particular population
      slice_tot_start = stan_data$rtrn |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = min(rowid), .groups = "drop") |> pluck("rowid"),
      slice_tot_end = stan_data$rtrn |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = max(rowid), .groups = "drop") |> pluck("rowid")
    )
  )
  
  return(stan_fit)
}

```

**Could get `stream_dist` from LU or sf_coord? Other fixed values here? As above, could avoid call to global `tbl_coho` for n_pop**

```{r stipm_functions}
stan_stipm <- function(stan_data, n_iter = 200, n_chain = 2){
  #note n_year does not include "+1" of AR1 since adult_pred is calc'd separately as
  # smolt[n_year]*surv[n_year], thereby giving adult run size (spwn+hvst) in n_year+1
  #stan_data$y_min_max accordingly is first:last_year_of_data
  stan_fit <- stan(
    file = 'LD_coho_forecast_6_2_4.stan', 
    iter = n_iter, chains = n_chain, thin = 1, seed = 222,
    control = list(adapt_delta = 0.99, max_treedepth = 10.25),
    data = list(
      n_year = length(stan_data$y_min_max), 
#n_pop = length(unique(tbl_coho$pop_id)), #number of populations in full dataset (should generally equal n_pop_tot with)
      n_pop = length(unique(coho_data_tbl$pop_id)), #number of populations in full dataset
      u = matrix(1, nrow = 1, ncol = length(unique(stan_data$spwn$pop_id))),
      dist = units::drop_units(sf::st_distance(sf_coord)/10000), #values are identical
      
      pop_smolt = unique(stan_data$smolt$pop_id), #pop_ids with smolt data 
      n_pop_smolt = length(unique(stan_data$smolt$pop_id)),
      smolt_true = stan_data$smolt$yr,
#      smolt_dat = stan_data$smolt$`Smolt Abundance`,
      smolt_dat = stan_data$smolt$smolt,
      n_smolt = nrow(stan_data$smolt),
      
      pop_esc = unique(stan_data$spwn$pop_id),  # pop_ids with escapement data
      n_pop_esc = length(unique(stan_data$spwn$pop_id)),
      esc_true = stan_data$spwn$yr,
      esc_dat = stan_data$spwn$spwn,
      n_esc = nrow(stan_data$spwn),
      
      pop_catch = unique(stan_data$hvst$pop_id), #pop_ids with harvest data
      n_pop_catch = length(unique(stan_data$hvst$pop_id)),
      harvest_true = stan_data$hvst$yr,
      harvest_dat = stan_data$hvst$hvst,
      n_harvest = nrow(stan_data$hvst),
      
      pop_MS = unique(stan_data$MS$pop_id), #pop_ids with marine survival data
      n_pop_MS = length(unique(stan_data$MS$pop_id)),
      MS_true = stan_data$MS$yr, #orig uses Fishery_Plus_Escapement rather than Release_No to filter...
#      MS_dat_x = stan_data$MS$Fishery_Plus_Escapement |> round(), #stan expects integer...
#      MS_dat_N = stan_data$MS$Release_No,
      MS_dat_x = stan_data$MS$est_n_rec |> round(), #stan expects integer...
      MS_dat_N = stan_data$MS$est_n_rel,
      n_MS = nrow(stan_data$MS),
      
      stream_dist = stan_data$spwn |> distinct(pop, hab_km) |> pluck("hab_km"),
      
      sigma_esc = 0.2,
      
      n_hatchery = filter(stan_data$MS, hat == 1) |> distinct(pop_id) |> nrow(),
      hatchery = distinct(stan_data$MS, pop_id, pop, hat) |> 
        mutate(hat_id = if_else(hat > 0, row_number(), NA_integer_)) |> 
        filter(!is.na(hat_id)) |> pluck("hat_id"),
      wild = distinct(stan_data$MS, pop_id, pop, hat) |> 
        mutate(hat_id = if_else(hat < 1, row_number(), NA_integer_)) |> 
        filter(!is.na(hat_id)) |> pluck("hat_id"), 
      
      slice_smolt_start = stan_data$smolt |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = min(rowid), .groups = "drop") |> pluck("rowid"),
      slice_smolt_end = stan_data$smolt |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = max(rowid), .groups = "drop") |> pluck("rowid"),
      
      slice_esc_start = stan_data$spwn |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = min(rowid), .groups = "drop") |> pluck("rowid"),
      slice_esc_end = stan_data$spwn |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = max(rowid), .groups = "drop") |> pluck("rowid"),
      
      slice_harvest_start = stan_data$hvst |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = min(rowid), .groups = "drop") |> pluck("rowid"),
      slice_harvest_end = stan_data$hvst |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = max(rowid), .groups = "drop") |> pluck("rowid"),
      
      slice_MS_start = stan_data$MS |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = min(rowid), .groups = "drop") |> pluck("rowid"),
      slice_MS_end = stan_data$MS |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = max(rowid), .groups = "drop") |> pluck("rowid")
    )
  )
  return(stan_fit)
}
```

## oat


```{r oat, eval=FALSE}
#verbose/redundant chunk, but explicit _lag2 and _lag1 for certainty/clarity
#intermediary single year output is saved out within map() in case of loop disruptions

p <- c(0.1, 0.5, 0.9)
#lu <- tbl_coho |> distinct(pop_id, pop)
iter <- 3000
chain <- 4
oat_year_min <- 1998
oat_years_max <- 2009:2017 #predicting 2010:2018
#a dataset year_max of 2014, predicting 2015, with default lags of 2 gives FRAM/spwn through 2012
#but with "compiling" lags of 1 gives FRAM/spwn through 2013

oat_lag2 <- set_names(oat_years_max) |> 
  map(function(x) {
    print(x)
    stan_data_list <- stan_data_filter(coho_data_tbl, year_min = oat_year_min, year_max = x, lag_spwn = 2, lag_hvst = 2) 
    print(stan_data_list$y_min_max)
    print(c("smolt", range(stan_data_list$smolt$year)))
    print(c("MS", range(stan_data_list$MS$year)))
    print(c("spwn", range(stan_data_list$spwn$year)))
    print(c("hvst", range(stan_data_list$hvst$year)))
    print(c("rtrn", range(stan_data_list$rtrn$year)))
    
    print(Sys.time())

    fit_ar1 <- stan_ar1(stan_data = stan_data_list, n_iter = iter, n_chain = chain)
    #recall stan data list arg n_year+1 relative to STIPM gives adult_pred in desired year
    fit_ar1_pred <- summary(fit_ar1, pars = "adult_pred", probs = p)$summary |>
      as.data.frame() |> rownames_to_column("stan_out") |> tibble() |>
      mutate(
        var = str_extract(stan_out, "[a-z]+[:punct:][a-z]+"),
        pop_id = as.numeric(str_extract(stan_out, "[0-9]+")),
        year = last(stan_data_list$y_min_max) + 1, #should be x+1
        mod = "ar1"
      ) |>
      left_join(distinct(coho_data_tbl, pop_id, pop, StockID), by = "pop_id")

    print(Sys.time())
    
    fit_stipm <- stan_stipm(stan_data = stan_data_list, n_iter = iter, n_chain = chain)
    #recall adult_pred is smolt[n_year]*surv[n_year] for adult run size (spwn+hvst) n_year+1
    fit_stipm_pred <- summary(fit_stipm, pars = "adult_pred", probs = p)$summary |>
      as.data.frame() |> rownames_to_column("stan_out") |> tibble() |>
      mutate(
        var = str_extract(stan_out, "[a-z]+[:punct:][a-z]+"),
        pop_id = as.numeric(str_extract(stan_out, "[0-9]+")),
        year = last(stan_data_list$y_min_max) + 1, #should be x+1
        mod = "stipm"
      ) |>
      left_join(distinct(coho_data_tbl, pop_id, pop, StockID), by = "pop_id")
    
    out <- bind_rows(fit_ar1_pred, fit_stipm_pred)
    saveRDS(out, paste0("oat_fits/oat_lag2_",x+1,".rds"))

    return(out)
  })


#identical to above other than lag_spwn and lag_hvst args in stan_data_filter()
oat_lag1 <- set_names(oat_years_max) |> 
  map(function(x) {
    print(x)
    stan_data_list <- stan_data_filter(coho_data_tbl, year_min = oat_year_min, year_max = x, lag_spwn = 1, lag_hvst = 1) 
    print(stan_data_list$y_min_max)
    print(c("smolt", range(stan_data_list$smolt$year)))
    print(c("MS", range(stan_data_list$MS$year)))
    print(c("spwn", range(stan_data_list$spwn$year)))
    print(c("hvst", range(stan_data_list$hvst$year)))
    print(c("rtrn", range(stan_data_list$rtrn$year)))

    print(Sys.time())

    fit_ar1 <- stan_ar1(stan_data = stan_data_list, n_iter = iter, n_chain = chain)
    fit_ar1_pred <- summary(fit_ar1, pars = "adult_pred", probs = p)$summary |>
      as.data.frame() |> rownames_to_column("stan_out") |> tibble() |>
      mutate(
        var = str_extract(stan_out, "[a-z]+[:punct:][a-z]+"),
        pop_id = as.numeric(str_extract(stan_out, "[0-9]+")),
        year = last(stan_data_list$y_min_max) + 1, #should be x+1
        mod = "ar1"
      ) |>
      left_join(distinct(coho_data_tbl, pop_id, pop, StockID), by = "pop_id")

    print(Sys.time())
    
    fit_stipm <- stan_stipm(stan_data = stan_data_list, n_iter = iter, n_chain = chain)
    fit_stipm_pred <- summary(fit_stipm, pars = "adult_pred", probs = p)$summary |>
      as.data.frame() |> rownames_to_column("stan_out") |> tibble() |>
      mutate(
        var = str_extract(stan_out, "[a-z]+[:punct:][a-z]+"),
        pop_id = as.numeric(str_extract(stan_out, "[0-9]+")),
        year = last(stan_data_list$y_min_max) + 1, #should be x+1
        mod = "stipm"
      ) |>
      left_join(distinct(coho_data_tbl, pop_id, pop, StockID), by = "pop_id")
    
    out <- bind_rows(fit_ar1_pred, fit_stipm_pred)
    saveRDS(out, paste0("oat_fits/oat_lag1_",x+1,".rds"))

    return(out)
  })


oat <- bind_rows(
  bind_rows(oat_lag2) |> mutate(lag = "l2")
  ,
  bind_rows(oat_lag1) |> mutate(lag = "l1")
)

saveRDS(oat, "oat_fits/oat_l2_l1_2010_2018.rds")

```


```{r oat_rhat_neff}
# oat |> 
#   group_by(lag_mod, pop_id, pop) |> 
#   summarise(Rhat_max = max(Rhat), n_eff_min = min(n_eff), .groups = "drop") |> 
#   pivot_wider(names_from = lag_mod, values_from = c(Rhat_max, n_eff_min)) |>
#   select(pop_id, pop, starts_with("Rhat"), starts_with("n_eff")) |> print(n = 40)

# #all years
# oat |> 
#   select(year, lag_mod, pop_id, pop, Rhat, n_eff) |> 
#   filter(pop_id == 34) |> 
#   #pivot_longer(-c(year, lag_mod, pop_id, pop), names_to = "var", values_to = "val") |> 
#   gt::gt(groupname_col = "year", rowname_col = "lag_mod") |> 
#   gt::cols_hide(c("pop_id", "pop")) |> 
#   gt::tab_header(title = "One-ahead Rhat and effective draws", subtitle = "Willapa Bay Natural") |> 
#   gt::fmt_number(Rhat, decimals = 2) |> gt::fmt_number(n_eff, decimals = 0)

#max/min
oat |>
  group_by(lag_mod, pop_id, pop) |>
  summarise(Rhat_max = max(Rhat), n_eff_min = min(n_eff), .groups = "drop") |>
  filter(pop_id == 34) |> 
  gt::gt(rowname_col = "lag_mod") |> 
  gt::cols_hide(c("pop_id", "pop")) |> 
  gt::tab_header(title = "One-ahead Rhat and effective draws", subtitle = "Willapa Bay Natural") |> 
  gt::fmt_number(Rhat_max, decimals = 2) |> gt::fmt_number(n_eff_min, decimals = 0)

```

```{r oat_obs, eval=FALSE}
(
oat_obs <- left_join(
  oat,
  coho_data_tbl |> select(year, pop_id, rtrn) |> 
    #adding MASE denominator
    group_by(pop_id) |> 
    mutate(
      scale_err = mean(abs(rtrn - c(NA, head(rtrn, -1))), na.rm = T)
    ) |> 
    ungroup(),
  by = c("year", "pop_id")
  ) |>
  select(lag_mod, StockID, pop_id, pop, year, scale_err, rtrn,  `10%`:`90%`) |> 
  mutate(
    in_10_90 = (rtrn >= `10%`) & (rtrn <= `90%`),
    err = rtrn - `50%`, #positive is underforecast, negative is "fewer than expected"
    err_abs = abs(err),
    err_log = log(rtrn) - log(`50%`),
    err_pct = err / rtrn,
    err_abs_pct = err_abs / rtrn,
    #kept as Eq26 in paper with pred-obs
    mase = abs(`50%` - rtrn) / scale_err
  )
)
```


```{r oat_obs_mase_by_lag}
#MASE ratios by lag
oat_obs |>
  select(pop_id, pop, lag_mod, year, mase) |>
  pivot_wider(names_from = lag_mod, values_from = mase) |> 
  mutate(
    l1_l2_ar1 = l1_ar1 / l2_ar1,
    l1_l2_stipm = l1_stipm / l2_stipm
  ) |> 
  group_by(pop_id, pop) |> 
  summarise(across(starts_with("l1_l2"), list(min = ~min(.), med = ~median(.), max = ~max(.)))) |> print(n = 50)
```


```{r}
# #WB focus
# coho_data_tbl |> filter(pop_id == 34) |> select(pop_id:StockID, year, spwn, hvst, rtrn) |> print(n = 50)
# oat_obs |> filter(pop_id == 34) |> filter(str_detect(lag_mod, "stipm"))


oat_obs |> filter(pop_id == 34) |>
  select(lag_mod, year, rtrn:`90%`, err:mase, in_10_90) |>
  filter(str_detect(lag_mod, "stipm")) |> arrange(lag_mod, year) |> 
  #gt(groupname_col = "year", rowname_col = "lag_mod")
  gt(groupname_col = "lag_mod", rowname_col = "year") |> 
  fmt_number(rtrn:err_abs, decimals = 0) |> 
  fmt_number(err_log:mase, decimals = 2) |> 
  summary_rows(groups = TRUE, fns = list(min = ~min(.), med = ~median(.), max = ~max(.)))
    

# rr <- bind_cols(
#   readxl::read_excel("O:/code/coho/forecast_wb/2021 WB4 Coho Forecast Model DRAFT 12.14.2020.xlsx", range = "RR!C38:C48", col_names = "year"),
#   readxl::read_excel("O:/code/coho/forecast_wb/2021 WB4 Coho Forecast Model DRAFT 12.14.2020.xlsx", range = "RR!E38:E48", col_names = "escp"),
#   readxl::read_excel("O:/code/coho/forecast_wb/2021 WB4 Coho Forecast Model DRAFT 12.14.2020.xlsx", range = "RR!U38:U48", col_names = "catch")) |> 
#   mutate(trs = escp + catch)



#all years, all pops
oat_obs |> 
  group_by(lag_mod) |> 
  summarise(
    n = n(),
    in_10_90_sum = sum(in_10_90),
    in_10_90_pct = in_10_90_sum / n,
    across(err:mase, median),
    .groups = "drop")

#all years by pop
oat_obs |> 
  group_by(lag_mod, pop_id, pop) |> 
  summarise(
    n = n(),
    in_10_90_sum = sum(in_10_90),
    in_10_90_pct = in_10_90_sum / n,
    across(err:mase, median),
    .groups = "drop") |> 
  filter(pop_id == 34)

# #values are terminal run sizes from regional workbook
# #catches do not include preterm, so escapements line up but t9$obs != stipm$rtrn 
# t9 <- readxl::read_excel("O:/code/coho/forecast_wb/table9_2020_submission.xlsx") |> 
#   mutate(
#     err = obs - mar_surv,
#     err_abs = abs(err),
#     err_log = log(obs) - log(mar_surv),
#     err_abs_pct = err_abs / obs
#   )
# 
# t9 |> filter(between(year, 2013, 2018)) |> summarise(across(err:err_abs_pct, median))
# oat_obs |> arrange(mod, year) |> 
#   filter(pop_id == 34) |> select(mod, year, rtrn, `10%`:`90%`, err:err_abs_pct) |> group_by(mod) |> summarise(across(err:err_abs_pct, median))

#the large returns in 2009 & 2010 seem to predispose overforecasts in 17 & 18
#ar1 bad but better than stipm in 2015
oat_obs |> 
  filter(pop_id > 30) |> 
  filter(pop_id == 34) |> 
  ggplot(aes(x = year, fill = lag_mod, color = lag_mod)) +
  scale_y_continuous("Return", labels = scales::comma) +
  wacolors::scale_fill_wa_d(aesthetics = c("fill", "color")) +
  geom_ribbon(aes(ymin = `10%`, ymax = `90%`), alpha = 0.2) + 
  geom_line(aes(y = `50%`)) +
  geom_point(aes(y = rtrn), color = 1)  +
  facet_wrap(~pop+lag_mod, scales = "free")


```


# Can delete soon

## LU export

Dump a file for discussion and review of included series.

```{r stipm_pops, eval=FALSE}
# tbl_coho |> 
#   group_by(pop_id, pop) |> 
#   summarise(
#     year_min = min(`Calendar Year`),
#     year_max = max(`Calendar Year`),
#     nobs_any = n(),
#     across(c(spwn, hvst, `Smolt Abundance`, Release_No), ~sum(!is.na(.))),
#     .groups = "drop"
#   ) |> #print(n = 50)
#   ##writexl::write_xlsx("stipm_pops_crosscheck.xlsx")

# #4 cases of missing KM/Lat/Long due to the orig sequence of dataset construction
# #where a few additional records are added after joining stream lengths
# #but expect to drop 7/7A and Pt Gamble anyway
# #also following orig approach on "median" of Lat/Long, though already uniform 
# #manually copied into working xlsx, leaving pop_id/pops to confirm matches before deleting
# tbl_coho |> 
#   filter(!is.na(KM)) |>
#   group_by(pop_id, pop) |> 
#   summarise(across(c(Longitude, Latitude, KM), median), .groups = "drop") |> 
#   write.table("clipboard", row.names = F)

# # add CWT marine survival info
# tbl_coho |> 
#   distinct(pop_id, pop,`Smolt Ocean Survival Population`, hat) |> 
#   filter(!is.na(hat)) |> 
#   select(pop_id, `Smolt Ocean Survival Population`, hat) |> 
#   right_join(tibble(pop_id = 1:36), by = "pop_id") |> arrange(pop_id) |> 
#   write.table("clipboard", row.names = F, na = "")

```

```{r try_tidybayes, eval=FALSE}
#could further examine library(tidybayes)? and/or library(bayesplot)?
library(tidybayes)

fit_ar1 |> 
  recover_types(tbl_coho_stan$rtrn) |> #not doing much since pops already numerically indexed
  spread_draws(adult_est[y,i]) |> #TMI?
  median_qi()
```

```{r demo_stretch_allpops, eval=FALSE}
library(slider)

#stretching: before = Inf, so cumulative
foo <- tbl_coho_stan$rtrn |> 
  #filter( pop_id %in% focal_popids) |> 
  select(year, pop_id, pop, rtrn) |>
  group_by(pop_id, pop) |> 
  mutate(
    rtrn_mu_cml = slide_dbl(rtrn, mean, .before = Inf),
    lm_fit = slide(
      .x = cur_data(), #the subset of rows
      .f = ~lm(rtrn ~ year, data = .x), #the thing to do to them
      .before = Inf, #how far back to look
      .complete = T
    ),
    lm_pred = lm_fit |> 
      map_dbl(~if_else(is.null(.x), NA_real_, last(.x$fitted.values)))
  ) |> 
  ungroup()

foo |> 
  select(-lm_fit) |> 
  filter(pop_id > 30) |> #reduce for plotting 
  pivot_longer(cols = -c(year, pop_id, pop), names_to = "var", values_to = "val") |> 
  {\(x) 
  ggplot(x, aes(year, val, color = var)) +
  geom_line(data = filter(x, var != "rtrn")) +
  geom_point(data = filter(x, var == "rtrn")) + 
  scale_x_continuous(n.breaks = 10,  guide = guide_axis(n.dodge = 2)) +
  facet_wrap(~pop_id, scales = "free", ncol = 1)
  }()
```

```{r test_2050s, eval=FALSE}
#further into future just with larger n_year? oh yes.

fit_ar1_test <- stan(
  file = 'LD_coho_forecast_AR_ind_2.stan',
  iter = 200, chains = 2, thin = 1, seed = 222,
  control = list(adapt_delta = 0.99, max_treedepth = 10.25),
  data = list(
    #Number of years (total, includes several missing years for some stocks)
    n_year = length(unique(tbl_coho$year))*2,
    #Number of total populations    
    n_pop = length(unique(tbl_coho$pop_id)),
    #Number of populations with return data
    n_pop_tot = length(unique(tbl_coho_stan$rtrn$pop_id)),
    #Which populations possess return data
    pop_tot = unique(tbl_coho_stan$rtrn$pop_id),
    #Length of the return data vectors
    n_tot = nrow(tbl_coho_stan$rtrn), #length(tot_dat)
    #Vectors of all return data across all populations
    tot_dat = tbl_coho_stan$rtrn$rtrn,
    #Vectors of the indices identifying which years are those with non-NA data for the return data
    tot_true = tbl_coho_stan$rtrn$yr,
    #Paired vectors of slice points indicating the beginning, and end of the data for a particular population
    slice_tot_start = tbl_coho_stan$rtrn |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = min(rowid), .groups = "drop") |> pluck("rowid"),
    slice_tot_end = tbl_coho_stan$rtrn |> rowid_to_column() |> group_by(pop_id) |> summarise(rowid = max(rowid), .groups = "drop") |> pluck("rowid")
    )
  )

fit_ar1_test_smry <- fit_smry(fit_ar1_test)

fit_ar1_test_smry$adult_est |> #tail() 
  filter(pop_id > 30) |> 
  ggplot(aes(x = year)) +
  scale_y_continuous("Estimated adult return", labels = scales::comma) +
  scale_fill_brewer(type = "qual", aesthetics = c("fill", "color") ) +
  geom_ribbon(aes(ymin = `10%`, ymax = `90%`), alpha = 0.2) + 
  geom_line(aes(y = `50%`)) +
  geom_point(
    data = tbl_coho_stan$rtrn |> filter(pop_id > 30) |> select(year, pop, pop_id, rtrn),
    aes(y = rtrn),
    inherit.aes = T) +
  facet_wrap(~pop)

```

